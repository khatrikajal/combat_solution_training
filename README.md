# Combat Solution Training â€“ Azure OpenAI + LangChain + LangGraph + Docker + DAG

## ğŸ“‚ Project Structure
```
combat_solution_training/
â”‚
â”œâ”€â”€ azure_openapi/      # Task 1: Azure OpenAI basics & API integration
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ call_azureOpenAPI.py
â”‚
â”œâ”€â”€ langchain/          # Task 2: LangChain basics
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ langchain_model.py
â”‚
â”œâ”€â”€ langgraph/          # Task 3: LangGraph chatbot workflow with azureopen ai
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ azureopenai_langgraph.py
â”‚
â”œâ”€â”€ dag/                # Task 5: DAG implementation with LangGraph
â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ Dockerfile          # Task 4: Containerization langgraph only 
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md           
```

---

## ğŸ“ Task Details

### **Task 1 â€“ Learn Azure OpenAI Basics**  
**Folder:** `azure_openapi/`  
**Objectives:**
- Understand Azure OpenAI vs OpenAI.com
- Access models via Azure portal
- Learn LLM concepts: tokens, prompts, completions
- Create Azure OpenAI resource in Azure Portal
- Configure API key & endpoint in `.env`

**Deliverables:**
- Azure OpenAI resource created
- Playground prompt tested
- `call_azureOpenAPI.py` to call Azure GPT-3.5 API using key & endpoint

---

### **Task 2 â€“ Learn LangChain Basics**  
**Folder:** `langchain/`  
**Objectives:**
- Learn LangChain concepts: LLMs, Chains, Memory, Tools
- Build a simple LangChain:
  - PromptTemplate
  - ChatOpenAI model
  - ConversationBufferMemory

**Deliverables:**
- LangChain script connecting prompt, LLM, and memory
- Tested with openrouter "mistralai/mistral-7b-instruct:free" model

---

### **Task 3 â€“ Build a Simple LangGraph Flow**  
**Folder:** `langgraph/`  
**Objectives:**
- Learn LangGraph concepts: Graph, Nodes, Edges, State Management
- Build a minimal chatbot:
  1. Input Node â†’ LLM Node (Azure GPT-3.5) â†’ Memory Node â†’ Output Node

**Deliverables:**
- `azureopenai_langgraph.py` with working chatbot flow

---

### **Task 4 â€“ Dockerize the LangGraph Chatbot**  
**Folder:** `langgraph/` (Docker runs from here)  
**Objectives:**
- Understand Docker basics: Image vs Container, Dockerfile, Docker Compose
- Create a containerized environment for LangGraph chatbot

**Deliverables:**
- `Dockerfile` & `docker-compose.yml`
- Runs chatbot in container with:
  ```bash
  docker-compose up --build
  ```
- Exposes chatbot at [http://localhost:8501](http://localhost:8501)

---

### **Task 5 â€“ DAG Implementation in LangGraph**  
**Folder:** `dag/`  
**Objectives:**
- Understand Directed Acyclic Graph (DAG) in LangGraph
- Implement branching workflow:
  - If input is calculation â†’ route to tool node
  - If input is text â†’ route to LLM node

**Deliverables:**
- Multi-path DAG script with decision-based routing
- No cycles; clean input-to-output flow

---

## âš™ï¸ Environment Variables
Each task folder contains its own `.env` file:
```env
ENDPOINT_URL=https://<your-resource-name>.openai.azure.com/
DEPLOYMENT_NAME=gpt-35-turbo
AZURE_OPENAI_API_KEY=<your-api-key>
```

---

## ğŸš€ How to Run
### Local (Python)
```bash
pip install -r requirements.txt
cd langgraph
python azureopenai_langgraph.py
```

### Docker
```bash
docker-compose up --build
```
Visit: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“– Learning Goals
- **Azure OpenAI**: Deploy & call GPT models from Azure portal  
- **LangChain**: Build LLM chains with memory  
- **LangGraph**: Create multi-node conversational flows  
- **Docker**: Package chatbot for consistent deployment  
- **DAG**: Build decision-based AI workflows  
